# üê≥ –ó–∞–ø—É—Å–∫ Ollama –≤ Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ

## üìã –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### –®–∞–≥ 1: –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Docker

–ï—Å–ª–∏ Docker –µ—â–µ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω:

```bash
# macOS
brew install --cask docker

# –ò–ª–∏ —Å–∫–∞—á–∞–π—Ç–µ —Å https://www.docker.com/products/docker-desktop
```

### –®–∞–≥ 2: –ó–∞–ø—É—Å—Ç–∏—Ç–µ Ollama –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä

```bash
cd backendCashStream
docker-compose up -d
```

–≠—Ç–æ –∑–∞–ø—É—Å—Ç–∏—Ç Ollama –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ.

### –®–∞–≥ 3: –ó–∞–≥—Ä—É–∑–∏—Ç–µ –º–æ–¥–µ–ª—å

```bash
# –ü–æ–¥–∫–ª—é—á–∏—Ç–µ—Å—å –∫ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—É –∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –º–æ–¥–µ–ª—å
docker exec -it cashstream-ollama ollama pull llama3.2:1b

# –ò–ª–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞:
docker exec -it cashstream-ollama ollama pull llama3.2:3b
```

### –®–∞–≥ 4: –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–∞–±–æ—Ç—É

```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ Ollama —Ä–∞–±–æ—Ç–∞–µ—Ç
curl http://localhost:11434/api/tags

# –ò–ª–∏ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ —á–∞—Ç
curl http://localhost:11434/api/chat -d '{
  "model": "llama3.2:1b",
  "messages": [
    {
      "role": "user",
      "content": "–ü—Ä–∏–≤–µ—Ç!"
    }
  ]
}'
```

## üîß –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–º

### –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
```bash
docker-compose stop
```

### –ó–∞–ø—É—Å—Ç–∏—Ç—å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
```bash
docker-compose start
```

### –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
```bash
docker-compose restart
```

### –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∏ —É–¥–∞–ª–∏—Ç—å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
```bash
docker-compose down
```

### –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –ª–æ–≥–∏
```bash
docker-compose logs -f ollama
```

### –£–¥–∞–ª–∏—Ç—å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –∏ –¥–∞–Ω–Ω—ã–µ (–≤–∫–ª—é—á–∞—è –º–æ–¥–µ–ª–∏)
```bash
docker-compose down -v
```

## üì¶ –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª—è–º–∏

### –°–ø–∏—Å–æ–∫ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
```bash
docker exec -it cashstream-ollama ollama list
```

### –ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å
```bash
docker exec -it cashstream-ollama ollama pull llama3.2:1b
```

### –£–¥–∞–ª–∏—Ç—å –º–æ–¥–µ–ª—å
```bash
docker exec -it cashstream-ollama ollama rm llama3.2:1b
```

### –ó–∞–ø—É—Å—Ç–∏—Ç—å –º–æ–¥–µ–ª—å (–¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)
```bash
docker exec -it cashstream-ollama ollama run llama3.2:1b
```

## üöÄ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –±–µ–∫–µ–Ω–¥–æ–º

–ü–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞, –≤–∞—à –±–µ–∫–µ–Ω–¥ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–¥–∫–ª—é—á–∏—Ç—Å—è –∫ Ollama –ø–æ –∞–¥—Ä–µ—Å—É `http://localhost:11434`.

–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤ `.env` —Ñ–∞–π–ª–µ –±–µ–∫–µ–Ω–¥–∞ —É–∫–∞–∑–∞–Ω–æ:

```env
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:1b
```

## üíæ –•—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö

–ú–æ–¥–µ–ª–∏ —Ö—Ä–∞–Ω—è—Ç—Å—è –≤ Docker volume `ollama-data`, –ø–æ—ç—Ç–æ–º—É –æ–Ω–∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –¥–∞–∂–µ –ø–æ—Å–ª–µ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞.

–ß—Ç–æ–±—ã –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Ä–∞–∑–º–µ—Ä volume:
```bash
docker volume inspect backendcashstream_ollama-data
```

## üî• GPU –ø–æ–¥–¥–µ—Ä–∂–∫–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

–ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å NVIDIA GPU –∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –µ–≥–æ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è:

1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html)

2. –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ —Å–µ–∫—Ü–∏—é `deploy` –≤ `docker-compose.yml`:
```yaml
deploy:
  resources:
    reservations:
      devices:
        - driver: nvidia
          count: 1
          capabilities: [gpu]
```

3. –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä:
```bash
docker-compose down
docker-compose up -d
```

## üêõ Troubleshooting

### –ü–æ—Ä—Ç 11434 —É–∂–µ –∑–∞–Ω—è—Ç
```bash
# –ù–∞–π–¥–∏—Ç–µ –ø—Ä–æ—Ü–µ—Å—Å
lsof -i :11434

# –û—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –µ–≥–æ –∏–ª–∏ –∏–∑–º–µ–Ω–∏—Ç–µ –ø–æ—Ä—Ç –≤ docker-compose.yml
```

### –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è
```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏
docker-compose logs ollama

# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ Docker –∑–∞–ø—É—â–µ–Ω
docker ps
```

### –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è
```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–æ—Å—Ç—É–ø–Ω–æ–µ –º–µ—Å—Ç–æ –Ω–∞ –¥–∏—Å–∫–µ
df -h

# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
docker-compose logs -f ollama
```

### –ú–µ–¥–ª–µ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–µ–Ω—å—à—É—é –º–æ–¥–µ–ª—å (1b –≤–º–µ—Å—Ç–æ 3b –∏–ª–∏ 7b)
- –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É –≤–∞—Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ RAM (–º–∏–Ω–∏–º—É–º 4GB –¥–ª—è 1b –º–æ–¥–µ–ª–∏)
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ GPU –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ

## üìä –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞

| –ú–æ–¥–µ–ª—å | –†–∞–∑–º–µ—Ä | RAM | –°–∫–æ—Ä–æ—Å—Ç—å | –ö–∞—á–µ—Å—Ç–≤–æ |
|--------|--------|-----|----------|----------|
| llama3.2:1b | ~1.3GB | 2GB | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê |
| llama3.2:3b | ~2GB | 4GB | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê |
| mistral:7b | ~4.1GB | 8GB | ‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê |

## ‚úÖ –ì–æ—Ç–æ–≤–æ!

–¢–µ–ø–µ—Ä—å Ollama —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ –∏ –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é! üéâ

